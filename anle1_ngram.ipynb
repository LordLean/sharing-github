{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "anle1_ngram.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNRFS8q4ZNbFxuNhSXzVffT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LordLean/sharing-github/blob/master/anle1_ngram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ1DMObWXht5"
      },
      "source": [
        "import os\n",
        "import random, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk import word_tokenize as tokenize\n",
        "\n",
        "import operator\n",
        "import nltk \n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "import tqdm\n",
        "\n",
        "# Download lab2 resources.\n",
        "os.system(\"gdown --id 1H26pdLFh2cDxU-NkflQHzcNCYWUgHCbX\")\n",
        "os.system(\"unzip lab2resources.zip\")\n",
        "\n",
        "# Download scc resources.\n",
        "os.system(\"gdown --id 155TLf2OdXtvfPD8VsWwI2YlHfjS8ph04\")\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEuqhFH5hRbg"
      },
      "source": [
        "def get_training_testing(training_dir,split=0.5):\n",
        "\n",
        "    filenames=os.listdir(training_dir)\n",
        "    n=len(filenames)\n",
        "    print(\"There are {} files in the training directory: {}\".format(n,training_dir))\n",
        "    # random.seed(53)  #if you want the same random split every time\n",
        "    random.shuffle(filenames)\n",
        "    index=int(n*split)\n",
        "    trainingfiles=filenames[:index]\n",
        "    heldoutfiles=filenames[index:]\n",
        "    return trainingfiles,heldoutfiles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUcl6cc3hS3y",
        "outputId": "04ddc181-4a14-440a-ac4d-4f3da9071154"
      },
      "source": [
        "parentdir=\"lab2resources/sentence-completion\"\n",
        "trainingdir=os.path.join(parentdir,\"Holmes_Training_Data\")\n",
        "training,testing=get_training_testing(trainingdir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 522 files in the training directory: lab2resources/sentence-completion/Holmes_Training_Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PDt1q87Xf-w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "6fdf6837-ab33-4fe7-fa1f-8e0771b08c68"
      },
      "source": [
        "class n_gram_language_model():\n",
        "    \n",
        "    def __init__(self,trainingdir,files=[], construct_params={}):\n",
        "        self.training_dir=trainingdir\n",
        "        self.files=files\n",
        "        # Constructor Parameters.\n",
        "        self.construct_params=construct_params\n",
        "        self.train()\n",
        "        \n",
        "    def train(self):    \n",
        "        self.unigram={}\n",
        "        self.bigram={}\n",
        "        self.trigram={}\n",
        "        self.quad_gram={}\n",
        "         \n",
        "        self._processfiles()\n",
        "        self._make_unknowns(known=self.construct_params.get(\"known\",2))\n",
        "        self._discount()\n",
        "        self._convert_to_probs()\n",
        "\n",
        "        self.magic_counter = {\"trigram\": 0, \"quad_gram\":0}\n",
        "        self.super_counter = {\"trigram\": 0, \"quad_gram\":0}\n",
        "        \n",
        "    \n",
        "    def _processline(self,line):\n",
        "        tokens=[\"__START\"]+tokenize(line)+[\"__END\"]\n",
        "        previous=\"__END\"\n",
        "        for i, token in enumerate(tokens):\n",
        "            # Unigram\n",
        "            self.unigram[token]=self.unigram.get(token,0)+1\n",
        "            # Bigram\n",
        "            current=self.bigram.get(previous,{})\n",
        "            current[token]=current.get(token,0)+1\n",
        "            self.bigram[previous]=current\n",
        "            previous=token\n",
        "            # Trigram\n",
        "            if i < len(tokens)-2:\n",
        "              # Next words.\n",
        "              next = tokens[i+1] \n",
        "              next_next = tokens[i+2]\n",
        "              # Get dictionaries.\n",
        "              inner = self.trigram.get(token,{})\n",
        "              innermost = inner.get(next,{})\n",
        "              innermost[next_next] = innermost.get(token,0) + 1\n",
        "              # Write frequencies to dictionaries.\n",
        "              inner[next] = innermost\n",
        "              self.trigram[token] = inner\n",
        "            # 4-gram\n",
        "            if i < len(tokens)-3:\n",
        "              # Next words.\n",
        "              next1 = tokens[i+1] \n",
        "              next2 = tokens[i+2]\n",
        "              next3 = tokens[i+3]\n",
        "              # Get dictionaries.\n",
        "              inner1 = self.quad_gram.get(token,{})\n",
        "              inner2 = inner1.get(next1,{})\n",
        "              inner3 = inner2.get(next2,{})\n",
        "              inner3[next3] = inner3.get(token,0) + 1\n",
        "              # Write frequencies to dictionaries.\n",
        "              inner2[next2] = inner3\n",
        "              inner1[next1] = inner2\n",
        "              self.quad_gram[token] = inner1\n",
        "\n",
        "                      \n",
        "            \n",
        "    \n",
        "    def _processfiles(self):\n",
        "        for afile in tqdm.tqdm(self.files):\n",
        "            # print(\"Processing {}\".format(afile))\n",
        "            try:\n",
        "                with open(os.path.join(self.training_dir,afile)) as instream:\n",
        "                    for line in instream:\n",
        "                        line=line.rstrip()\n",
        "                        if len(line)>0:\n",
        "                            self._processline(line)\n",
        "            except UnicodeDecodeError:\n",
        "                print(\"UnicodeDecodeError processing {}: ignoring rest of file\".format(afile))\n",
        "      \n",
        "            \n",
        "    def _convert_to_probs(self):\n",
        "        self.unigram={k:v/sum(self.unigram.values()) for (k,v) in self.unigram.items()}\n",
        "        self.bigram={key:{k:v/sum(adict.values()) for (k,v) in adict.items()} for (key,adict) in self.bigram.items()}\n",
        "        self.trigram={k1:{k2:{k3:v/sum(adict2.values()) for k3, v in adict2.items()} for k2, adict2 in adict1.items()} for k1, adict1 in self.trigram.items()}\n",
        "        self.quad_gram={k1:{k2:{k3:{k4:v/sum(adict3.values()) for k4, v in adict3.items()} for k3, adict3 in adict2.items()} for k2, adict2 in adict1.items()} for k1, adict1 in self.quad_gram.items()}\n",
        "        self.kn={k:v/sum(self.kn.values()) for (k,v) in self.kn.items()}\n",
        "    \n",
        "\n",
        "    def nextlikely(self,k=1,current=\"\",method=\"unigram\"):\n",
        "        #use probabilities according to method to generate a likely next sequence\n",
        "        #choose random token from k best\n",
        "        blacklist=[\"__START\",\"__UNK\",\"__DISCOUNT\"]\n",
        "        most_likely = []\n",
        "        if method==\"unigram\":\n",
        "            dist=self.unigram\n",
        "            #sort the tokens by unigram probability\n",
        "            most_likely=sorted(list(dist.items()),key=operator.itemgetter(1),reverse=True)\n",
        "        elif method == \"bigram\":\n",
        "            dist=self.bigram.get(current,self.bigram.get(\"__UNK\",{}))\n",
        "            most_likely=sorted(list(dist.items()),key=operator.itemgetter(1),reverse=True)\n",
        "        elif method == \"trigram\":\n",
        "            # Split context string for first and second context words.\n",
        "            context = current.split()\n",
        "            c1, c2 = context[0], context[1]\n",
        "            dist = self.trigram[c1][c2]\n",
        "            # Get all words with maximum value.\n",
        "            most_likely = [(k, _) for k, v in dist.items() if v == max(dist.values())]\n",
        "        elif method == \"quad_gram\":\n",
        "            context = current.split(\" \")\n",
        "            c1,c2,c3 = context[0], context[1], context[2]\n",
        "            dist = self.quad_gram[c1][c2][c3]\n",
        "            most_likely = [(k, _) for k, v in dist.items() if v == max(dist.values())]\n",
        "\n",
        "        #filter out any undesirable tokens\n",
        "        filtered=[w for (w,p) in most_likely if w not in blacklist]\n",
        "        #choose one randomly from the top k\n",
        "        res=random.choice(filtered[:k])\n",
        "        return res\n",
        "    \n",
        "    def generate(self,k=3,end=\"__END\",limit=20,method=\"bigram\",methodparams={}):\n",
        "        if method==\"\":\n",
        "            method=methodparams.get(\"method\",\"bigram\")\n",
        "        current=\"__START\"\n",
        "        tokens=[]\n",
        "        try: \n",
        "          # Trigram\n",
        "          if method==\"trigram\":\n",
        "            context_1 = current\n",
        "            context_2 = random.choice([key for key, adict in self.trigram[current].items()])\n",
        "            while context_2 != end and len(tokens)<limit:\n",
        "              current = \" \".join([context_1, context_2])\n",
        "              current = self.nextlikely(k=k, current=current, method=method)\n",
        "              tokens.append(current)\n",
        "              context_1 = context_2\n",
        "              context_2 = current\n",
        "            return \" \".join(tokens[:-1])\n",
        "          # Quad-Gram\n",
        "          elif method == \"quad_gram\":\n",
        "            context_1 = current\n",
        "            context_2 = random.choice([key for key, adict in self.quad_gram[context_1].items()])\n",
        "            context_3 = random.choice([key for key, adict in self.quad_gram[context_1][context_2].items()])\n",
        "            while context_3 != end and len(tokens) < limit: \n",
        "              current = \" \".join([context_1, context_2, context_3])\n",
        "              current = self.nextlikely(k=k, current=current, method=method)\n",
        "              tokens.append(current)\n",
        "              context_1 = context_2\n",
        "              context_2 = context_3\n",
        "              context_3 = current\n",
        "            return \" \".join(tokens[:-1])\n",
        "        except:\n",
        "          return self.generate(k=k,end=end,limit=limit,method=method,methodparams=methodparams)\n",
        "        while current!=end and len(tokens)<limit:\n",
        "            current=self.nextlikely(k=k,current=current,method=method)\n",
        "            tokens.append(current)\n",
        "        return \" \".join(tokens[:-1])\n",
        "    \n",
        "    \n",
        "    def get_prob(self,token,context=\"\",methodparams={}):\n",
        "        if methodparams.get(\"method\",\"unigram\")==\"unigram\":\n",
        "            return self.unigram.get(token,self.unigram.get(\"__UNK\",0))\n",
        "        else:\n",
        "            if methodparams.get(\"smoothing\",\"kneser-ney\")==\"kneser-ney\":\n",
        "                unidist=self.kn\n",
        "            else:\n",
        "                unidist=self.unigram\n",
        "            bigram=self.bigram.get(context[-1],self.bigram.get(\"__UNK\",{}))\n",
        "            big_p=bigram.get(token,bigram.get(\"__UNK\",0))\n",
        "            lmbda=bigram[\"__DISCOUNT\"]\n",
        "            uni_p=unidist.get(token,unidist.get(\"__UNK\",0))\n",
        "            #print(big_p,lmbda,uni_p)\n",
        "            p=big_p+lmbda*uni_p            \n",
        "            return p\n",
        "    \n",
        "    \n",
        "    def compute_prob_line(self,line,methodparams={}):\n",
        "        #this will add _start to the beginning of a line of text\n",
        "        #compute the probability of the line according to the desired model\n",
        "        #and returns probability together with number of tokens\n",
        "        \n",
        "        tokens=[\"__START\"]+tokenize(line)+[\"__END\"]\n",
        "        acc=0\n",
        "        acc+=math.log(1.0001)\n",
        "        if methodparams.get(\"method\", \"unigram\") in [\"unigram\", \"bigram\"]:\n",
        "          for i,token in enumerate(tokens[1:]):\n",
        "            acc+=math.log(self.get_prob(token,tokens[:i+1],methodparams))\n",
        "          return acc,len(tokens[1:])\n",
        "        # Trigram - nice & clean, endless if else statements - ha. \n",
        "        if methodparams.get(\"method\") == \"trigram\":\n",
        "          self.super_counter[\"trigram\"] +=1\n",
        "          try:\n",
        "            for i, token in enumerate(tokens[1:]):\n",
        "              if i < len(tokens[1:]) - 3 and len(tokens[1:]) >= 3:\n",
        "                word1, word2, word3 = tokens[i+1], tokens[i+1+1], tokens[i+1+2]\n",
        "                if word1 in self.trigram:\n",
        "                  if word2 in self.trigram[word1]:\n",
        "                    if word3 in self.trigram[word1][word2]:\n",
        "                      acc+=math.log(self.trigram[word1][word2][word3])\n",
        "                    else:\n",
        "                      acc+=math.log(self.trigram[word1][word2][\"__UNK\"])\n",
        "                  else:\n",
        "                    if word3 in self.trigram[word1][\"__UNK\"]:\n",
        "                      acc+=math.log(self.trigram[word1][\"__UNK\"][word3])\n",
        "                    else: \n",
        "                      acc+=math.log(self.trigram[word1][\"__UNK\"][\"__UNK\"])\n",
        "                else:\n",
        "                  if word2 in self.trigram[\"__UNK\"]:\n",
        "                    if word3 in self.trigram[\"__UNK\"][word2]:\n",
        "                      acc+=math.log(self.trigram[\"__UNK\"][word2][word3])\n",
        "                    else:\n",
        "                      acc+=math.log(self.trigram[\"__UNK\"][word2][\"__UNK\"])\n",
        "                  else:\n",
        "                    if word3 in self.trigram[\"__UNK\"][\"__UNK\"]:\n",
        "                      acc+=math.log(self.trigram[\"__UNK\"][\"__UNK\"][word3])\n",
        "                    else:\n",
        "                      acc+=math.log(self.trigram[\"__UNK\"][\"__UNK\"][\"__UNK\"])\n",
        "            return acc, len(tokens[1:])\n",
        "          except KeyError:\n",
        "            self.magic_counter[\"trigram\"] += 1\n",
        "            return acc, len(tokens[1:]) \n",
        "        # Quad_gram - same as above. FYI - if else if statements are used rather than if elif to enhance readability.\n",
        "        if methodparams.get(\"method\") == \"quad_gram\":\n",
        "          self.super_counter[\"quad_gram\"] +=1\n",
        "          try:\n",
        "            for i, token in enumerate(tokens[1:]):\n",
        "              if i < len(tokens[1:]) - 4 and len(tokens[1:]) >= 4:\n",
        "                word1, word2, word3, word4 = tokens[i+1], tokens[i+1+1], tokens[i+1+2], tokens[i+1+3]\n",
        "                if word1 in self.quad_gram:\n",
        "                  if word2 in self.quad_gram[word1]:\n",
        "                    if word3 in self.quad_gram[word1][word2]:\n",
        "                      if word4 in self.quad_gram[word1][word2][word3]:\n",
        "                        acc+=math.log(self.quad_gram[word1][word2][word3][word4])\n",
        "                      elif \"__UNK\" in self.quad_gram[word1][word2][word3]:\n",
        "                        acc+=math.log(self.quad_gram[word1][word2][word3][\"__UNK\"])\n",
        "                    else:\n",
        "                      if word4 in self.quad_gram[word1][word2][\"__UNK\"]:\n",
        "                        acc+=math.log(self.quad_gram[word1][word2][\"__UNK\"][word4])\n",
        "                      elif \"__UNK\" in self.quad_gram[word1][word2][\"__UNK\"]:\n",
        "                        acc+=math.log(self.quad_gram[word1][word2][\"__UNK\"][\"__UNK\"])\n",
        "                  else:\n",
        "                    if \"__UNK\" in self.quad_gram[word1]:\n",
        "                      if word3 in self.quad_gram[word1][\"__UNK\"]:\n",
        "                        if word4 in self.quad_gram[word1][\"__UNK\"][word3]:\n",
        "                          acc+=math.log(self.quad_gram[word1][\"__UNK\"][word3][word4])\n",
        "                        elif \"__UNK\" in self.quad_gram[word1][\"__UNK\"][word3]:\n",
        "                          acc+=math.log(self.quad_gram[word1][\"__UNK\"][word3][\"__UNK\"])\n",
        "                      else:\n",
        "                        if \"__UNK\" in self.quad_gram[word1][\"__UNK\"]:\n",
        "                          if word4 in self.quad_gram[word1][\"__UNK\"][\"__UNK\"]:\n",
        "                            acc+=math.log(self.quad_gram[word1][\"__UNK\"][\"__UNK\"][word4])\n",
        "                          elif \"__UNK\" in self.quad_gram[word1][\"__UNK\"][\"__UNK\"]:\n",
        "                            acc+=math.log(self.quad_gram[word1][\"__UNK\"][\"__UNK\"][\"__UNK\"]\n",
        "                else:\n",
        "                  if \"__UNK\" in self.quad_gram:\n",
        "                    if word2 in self.quad_gram[\"__UNK\"]:\n",
        "                      if word3 in self.quad_gram[\"__UNK\"][word2]:\n",
        "                        if word4 in self.quad_gram[\"__UNK\"][word2][word3]:\n",
        "                          acc+=math.log(self.quad_gram[\"__UNK\"][word2][word3][word4])\n",
        "                        elif \"__UNK\" in self.quad_gram[\"__UNK\"][word2][word3]:\n",
        "                          acc+=math.log(self.quad_gram[\"__UNK\"][word2][word3][\"__UNK\"])\n",
        "                      else:\n",
        "                        if word4 in self.quad_gram[\"__UNK\"][word2][\"__UNK\"]:\n",
        "                          acc+=math.log(self.quad_gram[\"__UNK\"][word2][\"__UNK\"][word4])\n",
        "                        elif \"__UNK\" in self.quad_gram[\"__UNK\"][word2][\"__UNK\"]:\n",
        "                          acc+=math.log(self.quad_gram[\"__UNK\"][word2][\"__UNK\"][\"__UNK\"])\n",
        "                    else:\n",
        "                      if \"__UNK\" in self.quad_gram[\"__UNK\"]:\n",
        "                        if word3 in self.quad_gram[\"__UNK\"][\"__UNK\"]:\n",
        "                          if word4 in self.quad_gram[\"__UNK\"][\"__UNK\"][word3]:\n",
        "                            acc+=math.log(self.quad_gram[\"__UNK\"][\"__UNK\"][word3][word4])\n",
        "                          elif \"__UNK\" in self.quad_gram[\"__UNK\"][\"__UNK\"][word3]:\n",
        "                            acc+=math.log(self.quad_gram[\"__UNK\"][\"__UNK\"][word3][\"__UNK\"])\n",
        "                        else:\n",
        "                          if \"__UNK\" in self.quad_gram[\"__UNK\"][\"__UNK\"]:\n",
        "                            if word4 in self.quad_gram[\"__UNK\"][\"__UNK\"][\"__UNK\"]:\n",
        "                              acc+=math.log(self.quad_gram[\"__UNK\"][\"__UNK\"][\"__UNK\"][word4])\n",
        "                            elif \"__UNK\" in self.quad_gram[\"__UNK\"][\"__UNK\"][\"__UNK\"]:\n",
        "                              acc+=math.log(self.quad_gram[\"__UNK\"][\"__UNK\"][\"__UNK\"][\"__UNK\"]\n",
        "            return acc, len(tokens[1:])\n",
        "          except KeyError:\n",
        "            self.magic_counter[\"quad_gram\"] += 1\n",
        "            return acc, len(tokens[1:]) \n",
        "            \n",
        "    \n",
        "    def compute_probability(self,filenames=[],methodparams={}):\n",
        "        #computes the probability (and length) of a corpus contained in filenames\n",
        "        if filenames==[]:\n",
        "            filenames=self.files\n",
        "        \n",
        "        total_p=0\n",
        "        total_N=0\n",
        "        for i,afile in enumerate(filenames):\n",
        "            print(\"Processing file {}:{}\".format(i,afile))\n",
        "            try:\n",
        "                with open(os.path.join(self.training_dir,afile)) as instream:\n",
        "                    for line in instream:\n",
        "                        line=line.rstrip()\n",
        "                        if len(line)>0:\n",
        "                            p,N=self.compute_prob_line(line,methodparams=methodparams)\n",
        "                            total_p+=p\n",
        "                            total_N+=N\n",
        "            except UnicodeDecodeError:\n",
        "                print(\"UnicodeDecodeError processing file {}: ignoring rest of file\".format(afile))\n",
        "        return total_p,total_N\n",
        "    \n",
        "    def compute_perplexity(self,filenames=[],methodparams={\"method\":\"bigram\",\"smoothing\":\"kneser-ney\"}):\n",
        "        \"\"\"\n",
        "        compute the probability and length of the corpus\n",
        "        calculate perplexity\n",
        "        lower perplexity means that the model better explains the data\n",
        "        \"\"\"\n",
        "        p,N=self.compute_probability(filenames=filenames,methodparams=methodparams)\n",
        "        # print(p,N)\n",
        "        if methodparams.get(\"method\") in [\"trigram\", \"quad_gram\"]:\n",
        "          rem = self.super_counter[methodparams.get(\"method\")] - self.magic_counter[methodparams.get(\"method\")]\n",
        "          pp=math.exp(-p/N) * (self.super_counter[methodparams.get(\"method\")]/rem)\n",
        "          return pp\n",
        "        pp=math.exp(-p/N)\n",
        "        return pp  \n",
        "    \n",
        "\n",
        "    def _make_unknowns(self,known=2):\n",
        "        # Unigram -----------------------------------\n",
        "        for (k,v) in list(self.unigram.items()):\n",
        "            if v<known:\n",
        "                del self.unigram[k]\n",
        "                self.unigram[\"__UNK\"]=self.unigram.get(\"__UNK\",0)+v\n",
        "        # Bigram -----------------------------------\n",
        "        for (k,adict) in list(self.bigram.items()):\n",
        "            for (kk,v) in list(adict.items()):\n",
        "                isknown=self.unigram.get(kk,0)\n",
        "                if isknown <= known:\n",
        "                    adict[\"__UNK\"]=adict.get(\"__UNK\",0)+v\n",
        "                    del adict[kk]\n",
        "            isknown=self.unigram.get(k,0)\n",
        "            if isknown <= known:\n",
        "                del self.bigram[k]\n",
        "                current=self.bigram.get(\"__UNK\",{})\n",
        "                current.update(adict)\n",
        "                self.bigram[\"__UNK\"]=current\n",
        "            else:\n",
        "                self.bigram[k]=adict\n",
        "        # Trigram -----------------------------------\n",
        "        for (k1, dict1) in list(self.trigram.items()):\n",
        "          for (k2, dict2) in list(dict1.items()):\n",
        "            for (k3, val) in list(dict2.items()):\n",
        "              isknown=self.unigram.get(k3,0)\n",
        "              if isknown == 0:\n",
        "                dict2[\"__UNK\"] = dict2.get(\"__UNK\",0) + val\n",
        "                del dict2[k3]\n",
        "            isknown=self.unigram.get(k2,0)\n",
        "            if isknown <= known:\n",
        "              del self.trigram[k1][k2]\n",
        "              current=self.trigram[k1].get(\"__UNK\",{})\n",
        "              current.update(dict2)\n",
        "              self.trigram[k1][\"__UNK\"] = current\n",
        "            else:\n",
        "              self.trigram[k1][k2] = dict2\n",
        "          # For first token:\n",
        "          isknown=self.unigram.get(k1,0)\n",
        "          if isknown <= known:\n",
        "            del self.trigram[k1]\n",
        "            current = self.trigram.get(\"__UNK\",{})\n",
        "            current.update(dict1)\n",
        "            self.trigram[\"__UNK\"] = current \n",
        "          else:\n",
        "            self.trigram[k1] = dict1\n",
        "        # Quad Gram -----------------------------------\n",
        "        for (k1, dict1) in list(self.quad_gram.items()):\n",
        "          for (k2, dict2) in list(dict1.items()):\n",
        "            for (k3, dict3) in list(dict2.items()):\n",
        "              for (k4, val) in list(dict3.items()):\n",
        "                # Next\n",
        "                isknown = self.unigram.get(k4,0)\n",
        "                if isknown <= known:\n",
        "                  dict3[\"__UNK\"] = dict3.get(\"__UNK\",0) + val\n",
        "                  del dict3[k4]\n",
        "              # Next\n",
        "              isknown=self.unigram.get(k3,0)\n",
        "              if isknown <= known:\n",
        "                del self.quad_gram[k1][k2][k3]\n",
        "                current = self.quad_gram[k1][k2].get(\"__UNK\", {})\n",
        "                current.update(dict3)\n",
        "                self.quad_gram[k1][k2][\"__UNK\"] = current\n",
        "              else:\n",
        "                self.quad_gram[k1][k2][k3] = dict3\n",
        "            # Next\n",
        "            isknown=self.unigram.get(k2,0)\n",
        "            if isknown <= known:\n",
        "              del self.quad_gram[k1][k2]\n",
        "              current = self.quad_gram[k1].get(\"__UNK\",{})\n",
        "              current.update(dict2)\n",
        "              self.quad_gram[k1][\"__UNK\"] = current\n",
        "            else:\n",
        "              self.quad_gram[k1][k2] = dict2\n",
        "          # Next\n",
        "          isknown=self.unigram.get(k1,0)\n",
        "          if isknown <= known:\n",
        "            del self.quad_gram[k1]\n",
        "            current = self.quad_gram.get(\"__UNK\", {})\n",
        "            current.update(dict1)\n",
        "            self.quad_gram[\"__UNK\"] = current\n",
        "          else:\n",
        "            self.quad_gram[k1] = dict1\n",
        "\n",
        "\n",
        "\n",
        "                \n",
        "    def _discount(self,discount=0.75):\n",
        "        #discount each bigram count by a small fixed amount\n",
        "        self.bigram={k:{kk:value-discount for (kk,value) in adict.items()}for (k,adict) in self.bigram.items()}\n",
        "        \n",
        "        #for each word, store the total amount of the discount so that the total is the same \n",
        "        #i.e., so we are reserving this as probability mass\n",
        "        for k in self.bigram.keys():\n",
        "            lamb=len(self.bigram[k])\n",
        "            self.bigram[k][\"__DISCOUNT\"]=lamb*discount\n",
        "            \n",
        "        #work out kneser-ney unigram probabilities\n",
        "        #count the number of contexts each word has been seen in\n",
        "        self.kn={}\n",
        "        for (k,adict) in self.bigram.items():\n",
        "            for kk in adict.keys():\n",
        "                self.kn[kk]=self.kn.get(kk,0)+1\n",
        "    "
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-119-ad68bfabfd48>\"\u001b[0;36m, line \u001b[0;32m251\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qAFL7-dhcVd",
        "outputId": "d4554063-a55e-40a4-b525-45ad85ae5b36"
      },
      "source": [
        "MAX_FILES=5\n",
        "\n",
        "construct_params = {\n",
        "    \"known\" : 0\n",
        "}\n",
        "\n",
        "# Initialize n-gram language model.\n",
        "lm=n_gram_language_model(trainingdir=trainingdir,files=training[:MAX_FILES], construct_params=construct_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:08<00:00,  1.68s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_3D4k7P3Vph"
      },
      "source": [
        "def get_lengths(lm):\n",
        "  len_dict = {}\n",
        "  # Unigram\n",
        "  len_dict[\"unigram\"] = len(lm.unigram)\n",
        "  # Bigram\n",
        "  total = 0\n",
        "  for k1, d1, in lm.bigram.items():\n",
        "    total += len(d1)\n",
        "  len_dict[\"bigram\"] = total\n",
        "  # Trigram\n",
        "  total = 0\n",
        "  for k1, d1, in lm.trigram.items():\n",
        "    for k2, d2 in d1.items():\n",
        "      total += len(d2)\n",
        "  len_dict[\"trigram\"] = total\n",
        "  # Quad_gram\n",
        "  total = 0\n",
        "  for k1, d1, in lm.quad_gram.items():\n",
        "    for k2, d2 in d1.items():\n",
        "      for k3, d3 in d2.items():\n",
        "        total += len(d3)\n",
        "  len_dict[\"quad_gram\"] = total\n",
        "\n",
        "  return len_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx5g_PpI9gll",
        "outputId": "bd424597-b81c-4acc-93e4-bc32a9de290e"
      },
      "source": [
        "get_lengths(lm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bigram': 171398, 'quad_gram': 383331, 'trigram': 318582, 'unigram': 20184}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XznhU-qNCgww",
        "outputId": "54a34a50-605e-4c96-e83d-0102543ab5af"
      },
      "source": [
        "lm.files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TOTAM10.TXT', 'PRESC10.TXT', 'WLDFL10.TXT', 'BCITY10.TXT', '39STP10.TXT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU3xXjFGyidF",
        "outputId": "165a4984-0d27-48a4-b9ba-5cabc95cd6f8"
      },
      "source": [
        "for method in [\"unigram\", \"bigram\", \"trigram\"]:\n",
        "  print(method)\n",
        "  print(lm.compute_perplexity([\"BABSU10.TXT\"], methodparams={\"method\":method}))\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unigram\n",
            "Processing file 0:BABSU10.TXT\n",
            "66.32139148438647\n",
            "\n",
            "bigram\n",
            "Processing file 0:BABSU10.TXT\n",
            "32.41842930441104\n",
            "\n",
            "trigram\n",
            "Processing file 0:BABSU10.TXT\n",
            "21.412328391670034\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-_c0kMp3NmO",
        "outputId": "6e2a06bf-5d94-4d80-c2f5-d1591707cafe"
      },
      "source": [
        "lm.super_counter, lm.magic_counter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'quad_gram': 0, 'trigram': 0}, {'quad_gram': 0, 'trigram': 0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_odZHAi4nPy",
        "outputId": "c5e2dc23-e3e1-4dba-faaa-d2b39fa0ec76"
      },
      "source": [
        "s = \"__START this is a test sentence hello\"\n",
        "s = s.split()\n",
        "for i, token in enumerate(s):\n",
        "  if i < len(s) - 2:\n",
        "    print(token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__START\n",
            "this\n",
            "is\n",
            "a\n",
            "test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyoznr2CPA3x",
        "outputId": "10dd1d8b-bc71-47bd-94d9-f8f7ce2c5b5d"
      },
      "source": [
        "[lm.generate(method=\"quad_gram\", limit=30) for i in range(100)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"how much of their neighbor 's affairs the new generations\",\n",
              " \"has a child will do very well . ''\",\n",
              " 'fast as they could . You',\n",
              " 'and looked out over Shoshone Land , but before',\n",
              " 'half so large',\n",
              " 'I had bought ground and built me a house beside',\n",
              " 'days , till they fell in the traces to jerk',\n",
              " 'upon him with the coming of the night',\n",
              " ', eating their bit',\n",
              " 'time Spitz went through , dragging the whole team after',\n",
              " 'in great numbers',\n",
              " '',\n",
              " 'to Las Uvas',\n",
              " 'But the weather',\n",
              " ', the death of one or the',\n",
              " 'far back in the canon tangles is more',\n",
              " 'But if you',\n",
              " 'little apart from his family that he might meet it as became',\n",
              " \"''\",\n",
              " 'the wild almond passes into the',\n",
              " ', you can receive',\n",
              " 'down the Yukon',\n",
              " 'and Salt Water . Perrault was a',\n",
              " 'rain is over and gone they are stirred by the',\n",
              " \"''\",\n",
              " 'with the',\n",
              " 'cunning brush shelters from which the Shoshones shot',\n",
              " 'mesa one sees',\n",
              " ', though not half so large',\n",
              " 'surprised , too ;',\n",
              " 'he forgot the pain of',\n",
              " 'had',\n",
              " 'pines where the slope of',\n",
              " 'They laid up on the',\n",
              " 'grow there only . There is a',\n",
              " '',\n",
              " 'Etext of The Call of the Wild',\n",
              " 'one or more of the',\n",
              " \"his feet , he saw a woman . `` Mercedes '' the men\",\n",
              " '',\n",
              " 'To them , this was the one',\n",
              " 'the field , and on warm mornings makes',\n",
              " 'but they had',\n",
              " 'a man by her own hand ,',\n",
              " 'you do or cause :',\n",
              " 'one day going out what had taken place',\n",
              " 'He lay',\n",
              " \"made Dawson , and should have had a ten days ' or a week 's\",\n",
              " 'And on no day',\n",
              " 'it was called . It stood back from the road ,',\n",
              " 'to the sky , a long fall of soft',\n",
              " 'under the shadow of a drift , one looks to find',\n",
              " ', so that we find',\n",
              " '',\n",
              " 'huskies were added to the six of the original',\n",
              " 'belt of river trees .',\n",
              " 'big for her . The Indian woman gets nearly the same',\n",
              " 'sprang away into the woods . The wolves swung in behind ,',\n",
              " 'at the teeth of many dogs , so many days ,',\n",
              " 'on his neck and shoulders , being',\n",
              " 'drop out at any moment .',\n",
              " 'to bring away , but retreated around and around the camp ,',\n",
              " '',\n",
              " 'the shoulder . Thornton was running behind ,',\n",
              " 'this , not so',\n",
              " 'these things put him out of countenance .',\n",
              " ', the pool is never quite dry , but dark and bitter ,',\n",
              " 'then up the side of the canon till he came to no harm in it ; it is the land of timber and streams . There he',\n",
              " '',\n",
              " 'and there were those present who knew how it',\n",
              " 'down from the pine',\n",
              " 'Thornton . He',\n",
              " 'that alter the face of the earth ,',\n",
              " 'about .',\n",
              " 'lake can be at the highest point , it is perhaps true only as the things their eyes saw',\n",
              " 'under the rain of blows . A hundred',\n",
              " 'muzzle to the eyes in warm blood .',\n",
              " 'It would have required an experienced man to keep the country',\n",
              " '',\n",
              " 'the wild almond passes into the',\n",
              " 'without snarling and bristling , It led straight toward camp and John Thornton . He',\n",
              " 'and Perrault . Like other men , they passed out of',\n",
              " 'Illinois',\n",
              " 'But the weather',\n",
              " 'the',\n",
              " 'and over the face of the',\n",
              " 'everything that grows in these borders .',\n",
              " 'and all their stems',\n",
              " \"my country , a day 's travel ; and if he failed to find it ,\",\n",
              " ', and that as he',\n",
              " \". ''\",\n",
              " 'as the Pocket Hunter had been looking',\n",
              " 'Joe had lost an eye ; while Billee , the good-natured , was less good-natured , and',\n",
              " '',\n",
              " 'on the head as he lay in the traces and the sled , and',\n",
              " 'We had',\n",
              " \"Francois 's breath .\",\n",
              " 'Pike .',\n",
              " 'The rest of the team , making the next dog , Sol-leks ,',\n",
              " 'the fact .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "1n1aJbkZTVzg",
        "outputId": "a4ad0423-6e2b-49f7-ff8d-4c9d8553cb4c"
      },
      "source": [
        "s = \"he went to his desk after breakfast , these remarks : `` __UNK about\"\n",
        "s = s.split()\n",
        "word1, word2, word3 = s[-3],s[-2],s[-1]\n",
        "lm.quad_gram[word1][word2][word3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-87769efe52f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mword1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquad_gram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'about'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LKCHXTaUqcr"
      },
      "source": [
        "repeated quad_grams are so infrequent its often equal probability for the next word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZnklD5JxNsp"
      },
      "source": [
        "# Questions and Answers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfQqXooNNlvP"
      },
      "source": [
        "import pandas as pd, csv\n",
        "questions=os.path.join(parentdir,\"testing_data.csv\")\n",
        "answers=os.path.join(parentdir,\"test_answer.csv\")\n",
        "\n",
        "with open(questions) as instream:\n",
        "    csvreader=csv.reader(instream)\n",
        "    lines=list(csvreader)\n",
        "qs_df=pd.DataFrame(lines[1:],columns=lines[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7P-4UZtNlvR"
      },
      "source": [
        "##  Building and evaluating an SCC system\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Mos5VvNlvT"
      },
      "source": [
        "class question:\n",
        "    \n",
        "\n",
        "    def __init__(self,aline):\n",
        "        self.fields=aline\n",
        "        self.num2letter = {\n",
        "            0:\"a\",\n",
        "            1:\"b\",\n",
        "            2:\"c\",\n",
        "            3:\"d\",\n",
        "            4:\"e\"\n",
        "            }\n",
        "        self.tokenized = tokenize(self.fields[1])\n",
        "        self.options = self.fields[2:7]\n",
        "          \n",
        "\n",
        "    def get_field(self,field):\n",
        "        return self.fields[question.colnames[field]]\n",
        "    \n",
        "\n",
        "    def add_answer(self,fields):\n",
        "        self.answer=fields[1]\n",
        "   \n",
        "\n",
        "    def get_context(self,window,target=\"_____\",method=\"left\"):\n",
        "      for i, token in enumerate(self.tokenized):\n",
        "        if token == target:\n",
        "          if method==\"left\":\n",
        "            return self.tokenized[i-window:i]\n",
        "          elif method==\"right\": \n",
        "            return self.tokenized[i+1:i+1+window]\n",
        "\n",
        "\n",
        "    def chooseA(self):\n",
        "        return(\"a\")\n",
        "\n",
        "\n",
        "    def random(self):\n",
        "      \"\"\"\n",
        "      Retrun random choice of letter.\n",
        "      \"\"\"\n",
        "      return random.choice(self.num2letter)\n",
        "\n",
        "\n",
        "    def unigram(self):\n",
        "      \"\"\"\n",
        "      Return position of word with greatest unigram probability. 0 otherwise.\n",
        "      \"\"\"\n",
        "      option_probs = [lm.unigram[word] if word in lm.unigram else 0 for word in self.options]\n",
        "      index = option_probs.index(max(option_probs))\n",
        "      return self.num2letter[index]\n",
        "\n",
        "\n",
        "    def bigram(self, context_dir=\"left\"):\n",
        "      \"\"\"\n",
        "      Return position of word-pair with greatest bigram probability. 0 otherwise. \n",
        "      \"\"\"\n",
        "      context = self.get_context(1, method=context_dir)[0] # [0] to delist context.\n",
        "      if context_dir == \"left\":\n",
        "        option_probs = [lm.bigram[context][word] if context in lm.bigram and word in lm.bigram[context] else 0 for word in self.options]\n",
        "      elif context_dir == \"right\":\n",
        "        option_probs = [lm.bigram[word][context] if word in lm.bigram and context in lm.bigram[word] else 0 for word in self.options]\n",
        "      index = option_probs.index(max(option_probs))\n",
        "      return self.num2letter[index]\n",
        "\n",
        "\n",
        "    def trigram(self, context_dir=\"left\"):\n",
        "      \"\"\"\n",
        "      Return position of word-group with greatest trigram probability. 0 otherwise. \n",
        "      \"\"\"\n",
        "      option_probs = []\n",
        "      context = self.get_context(2, method=context_dir)\n",
        "      if context_dir == \"left\":\n",
        "        for word in self.options:\n",
        "          if context[0] in lm.trigram and context[1] in lm.trigram[context[0]] and word in lm.trigram[context[0]][context[1]]:\n",
        "            option_probs.append(lm.trigram[context[0]][context[1]][word])\n",
        "          # Back off to bigram.\n",
        "          elif context[1] in lm.bigram and word in lm.bigram[context[1]]:\n",
        "            option_probs.append(lm.bigram[context[1]][word])\n",
        "          # Back off to unigram.\n",
        "          elif word in lm.unigram:\n",
        "            option_probs.append(lm.unigram[word])\n",
        "          # Else 0.\n",
        "          else:\n",
        "            option_probs.append(0)\n",
        "      index = option_probs.index(max(option_probs))\n",
        "      return self.num2letter[index]\n",
        "\n",
        "\n",
        "    def quad_gram(self, context_dir=\"left\"):\n",
        "      \"\"\"\n",
        "      Return position of word-group with greatest trigram probability. 0 otherwise. \n",
        "      \"\"\"\n",
        "      option_probs = []\n",
        "      context = self.get_context(3, method=context_dir)\n",
        "      con_len = len(context)\n",
        "      for word in self.options:\n",
        "        if con_len == 3 and context[0] in lm.quad_gram and context[1] in lm.quad_gram[context[0]] and context[2] in lm.quad_gram[context[0]][context[1]] and word in lm.quad_gram[context[0]][context[1]][context[2]]:\n",
        "          option_probs.append(lm.quad_gram[context[0]][context[1]][context[2]][word])\n",
        "        # Back off to trigram.\n",
        "        elif con_len == 2 and context[1] in lm.trigram and context[2] in lm.trigram[context[1]] and word in lm.trigram[context[1]][context[2]]:\n",
        "          option_probs.append(lm.trigram[context[1]][context[2]][word])\n",
        "        # Back off to bigram.\n",
        "        elif con_len == 1 and context[2] in lm.bigram and word in lm.bigram[context[2]]:\n",
        "          option_probs.append(lm.bigram[context[2]][word])\n",
        "        # Back off to unigram.\n",
        "        elif con_len == 0 and word in lm.unigram:\n",
        "          option_probs.append(lm.unigram[word])\n",
        "        # Else 0.\n",
        "        else:\n",
        "          option_probs.append(0)\n",
        "      index = option_probs.index(max(option_probs))\n",
        "      return self.num2letter[index]\n",
        "    \n",
        "    \n",
        "    def predict(self, method=\"chooseA\", additional_args=None):\n",
        "        if method==\"chooseA\":\n",
        "          return self.chooseA()\n",
        "        elif method==\"random\":\n",
        "          return self.random()\n",
        "        elif method==\"unigram\":\n",
        "          return self.unigram()\n",
        "        elif method==\"bigram\":\n",
        "          return self.bigram()\n",
        "        elif method==\"trigram\":\n",
        "          return self.trigram()\n",
        "        elif method==\"quad_gram\":\n",
        "          return self.quad_gram()\n",
        "\n",
        "\n",
        "    def predict_and_score(self, method=\"chooseA\", additional_args=None):\n",
        "        #compare prediction according to method with the correct answer\n",
        "        #return 1 or 0 accordingly\n",
        "        prediction=self.predict(method=method, additional_args=additional_args)\n",
        "        if prediction == self.answer:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR5JVkwtuYdF"
      },
      "source": [
        "class scc_reader:\n",
        "    \n",
        "\n",
        "    def __init__(self,qs=questions,ans=answers):\n",
        "        self.qs=qs\n",
        "        self.ans=ans\n",
        "        self.read_files()\n",
        "\n",
        "\n",
        "    def read_files(self):\n",
        "        \n",
        "        #read in the question file\n",
        "        with open(self.qs) as instream:\n",
        "            csvreader=csv.reader(instream)\n",
        "            qlines=list(csvreader)\n",
        "        \n",
        "        #store the column names as a reverse index so they can be used to reference parts of the question\n",
        "        question.colnames={item:i for i,item in enumerate(qlines[0])}\n",
        "        \n",
        "        #create a question instance for each line of the file (other than heading line)\n",
        "        self.questions=[question(qline) for qline in qlines[1:]]\n",
        "        \n",
        "        #read in the answer file\n",
        "        with open(self.ans) as instream:\n",
        "            csvreader=csv.reader(instream)\n",
        "            alines=list(csvreader)\n",
        "            \n",
        "        #add answers to questions so predictions can be checked    \n",
        "        for q,aline in zip(self.questions,alines[1:]):\n",
        "            q.add_answer(aline)\n",
        "\n",
        "\n",
        "    def get_field(self,field):\n",
        "        return [q.get_field(field) for q in self.questions] \n",
        "    \n",
        "\n",
        "    def predict(self,method=\"chooseA\"):\n",
        "        return [q.predict(method=method) for q in self.questions]\n",
        "    \n",
        "    def predict_and_score(self,method=\"chooseA\", additional_args=None):\n",
        "        scores=[q.predict_and_score(method=method, additional_args=additional_args) for q in self.questions]\n",
        "        return sum(scores)/len(scores)\n",
        "\n",
        "SCC = scc_reader(questions, answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySm893cF8v59"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL3i2ZO9k1Uf"
      },
      "source": [
        "## No Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "b2KvDD3nNlvV",
        "outputId": "f3e2789a-c546-4be0-9ec3-e89502967967"
      },
      "source": [
        "methods = [\n",
        "           \"unigram\", \"bigram\", \"trigram\", \"quad_gram\",\n",
        "           ]\n",
        "\n",
        "skipped = [\"GloVe_cos\", \"GloVe_euc\",\n",
        "           \"spacy\", \"spacy_no_stopwords\"\n",
        "           ]\n",
        "\n",
        "df = pd.DataFrame({method: SCC.predict_and_score(method) for method in methods if method not in skipped}.items(), columns=[\"Method\", \"Score\"])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-587b81405914>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m            ]\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSCC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_and_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskipped\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Method\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    }
  ]
}